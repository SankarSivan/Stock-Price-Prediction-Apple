{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMdu6BuiodfRfxFkt8nthVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SankarSivan/Stock-Price-Prediction-Apple/blob/main/Stock_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "tXR6_1DM4ZWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "F5ydpFUW4ZKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfiU-VF54A2R"
      },
      "outputs": [],
      "source": [
        "# prompt: import data from github\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/SankarSivan/Stock-Price-Prediction-Apple/main/AAPL.csv'\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PB-Gj7Np4W-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "LXfFObhL4W7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iU2jc2MYvejw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill missing values\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "id": "CrPTHzLS8R4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no remaining nulls\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "LDrpmlz-8UXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "metadata": {
        "id": "7xxUaTHQvq-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "1Li5X7jGv2yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "df['Date'] = df['Date'].apply(pd.to_datetime)"
      ],
      "metadata": {
        "id": "P-qm44wAwAHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ZpUkA_QvwmiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns= ['Open', 'High', 'Low', 'Adj Close', 'Volume'], inplace =True)"
      ],
      "metadata": {
        "id": "TIe52EkNwgF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tuHY1DaLxAil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close'].plot(figsize=(12,6))"
      ],
      "metadata": {
        "id": "6DGt6BWyxXP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Kcmap1u1yNsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df[['Close']])"
      ],
      "metadata": {
        "id": "1sIIpcT0NAnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n",
        "def create_sequences(data, seq_len=60, pred_gap=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len - pred_gap + 1):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len+pred_gap-1])  # Predicting gap days ahead\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "VJfWcLA_8q6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: For 1, 5, 10 day forecasts\n",
        "X_1, y_1 = create_sequences(scaled_data, pred_gap=1)\n",
        "X_5, y_5 = create_sequences(scaled_data, pred_gap=5)\n",
        "X_10, y_10 = create_sequences(scaled_data, pred_gap=10)"
      ],
      "metadata": {
        "id": "vr94Jp8e8veq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X, y = create_sequences(scaled_data, pred_gap=1)\n",
        "split = int(0.75 * len(X_1))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "GWqhSteM8xte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN Model"
      ],
      "metadata": {
        "id": "QHdMkaTF86K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "1kaFN8ls82RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(units=50, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "dKQkbmN982OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = build_rnn_model((X_train.shape[1], X_train.shape[2]))\n",
        "rnn_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TE0wHhy482LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary()"
      ],
      "metadata": {
        "id": "M75TN4gZms93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "p5zs1KlS9QTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oZF5OGajnPqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "oQiATgJO82H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model building\n",
        "def build_lstm_model(input_shape, units = 50, Dropout_rate = 0.2, learning_rate = 0.001):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = units, return_sequences = False, input_shape = input_shape))\n",
        "    model.add(Dropout(Dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile ( optimizer = Adam(learning_rate = learning_rate), loss = 'mse')\n",
        "    return model\n",
        "\n",
        "# Model Excution\n",
        "lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
        "lstm_model.fit(X_train, y_train, epochs = 10, batch_size = 64, validation_split =0.2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xbRFVfXn82FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()"
      ],
      "metadata": {
        "id": "ZsJ0zyjFna0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Models"
      ],
      "metadata": {
        "id": "hvKuhx_4Af-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "JMMsCTupiDb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test, scaler):\n",
        "    pred_scaled = model.predict(X_test)\n",
        "    pred = scaler.inverse_transform(np.concatenate([pred_scaled, np.zeros((len(pred_scaled), 1))], axis=1))[:,0]\n",
        "    true = scaler.inverse_transform(np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), 1))], axis=1))[:,0]\n",
        "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
        "    mae = mean_absolute_error(true, pred)\n",
        "    return rmse, mae\n",
        "\n",
        "rmse_rnn, mae_rnn = evaluate(rnn_model, X_test, y_test, scaler)\n",
        "rmse_lstm, mae_lstm = evaluate(lstm_model, X_test, y_test, scaler)\n",
        "\n",
        "print(f\"SimpleRNN RMSE: {rmse_rnn:.2f}, MAE: {mae_rnn:.2f}\")\n",
        "print(f\"LSTM RMSE: {rmse_lstm:.2f}, MAE: {mae_lstm:.2f}\")"
      ],
      "metadata": {
        "id": "oaYzwvw8iLvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict and inverse scale\n",
        "y_pred = lstm_model.predict(X_test)\n",
        "y_pred_rescaled = scaler.inverse_transform(np.concatenate([y_pred, np.zeros((len(y_pred),df.shape[1]-1))], axis = 1))[:,0]\n",
        "y_test_rescaled = scaler.inverse_transform(np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), df.shape[1]-1))], axis = 1)) [:,0]\n"
      ],
      "metadata": {
        "id": "Q1egnow99yUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "results = []"
      ],
      "metadata": {
        "id": "Q0BPc40PUWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "omTPOftg8ybQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the Actual vs Predicted\n",
        "plt.figure(figsize = (12,5) )\n",
        "plt.plot(y_test_rescaled, label = 'Actual')\n",
        "plt.plot(y_pred_rescaled, label = 'Predicted')\n",
        "plt.legend()\n",
        "plt.title(' Stock Price Prediction')"
      ],
      "metadata": {
        "id": "xUoItSRt9yRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV"
      ],
      "metadata": {
        "id": "Yvqvcjs0FHoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "PxCW9vA6rmVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(units=50, dropout=0.2, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss=\"mse\", optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model"
      ],
      "metadata": {
        "id": "DKlIhCE_rmSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = KerasRegressor(model=build_model, verbose=0, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "5JQynyaFrmP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"model__units\": [32, 50, 64],\n",
        "    \"model__learning_rate\": [0.001, 0.005],\n",
        "    \"batch_size\": [32],\n",
        "    \"epochs\": [10, 20]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(reg, param_grid, scoring=\"neg_mean_squared_error\", cv=3, verbose=2)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)"
      ],
      "metadata": {
        "id": "1iLfACh1rmNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "2WqXjExTt07p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "-fzxJPuUt64U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load data ---\n",
        "df = pd.read_csv(url, parse_dates=[\"Date\"], index_col=\"Date\")[[\"Close\"]]\n",
        "df.fillna(method=\"ffill\", inplace=True)\n",
        "\n",
        "\n",
        "# --- Scale data 0â€‘1 ---\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "\n",
        "# --- Build 60â€‘step sequences to predict nextâ€‘day price ---\n",
        "SEQ_LEN, GAP = 60, 1\n",
        "X, y = [], []\n",
        "for i in range(len(scaled) - SEQ_LEN - GAP + 1):\n",
        "    X.append(scaled[i:i+SEQ_LEN])\n",
        "    y.append(scaled[i+SEQ_LEN+GAP-1])\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Train / validation split\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "y_train, y_val = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "X8ITD-AXtAkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    \"units\":        [32, 64],\n",
        "    \"learning_rate\": [0.001, 0.005],\n",
        "    \"epochs\":       [10, 20]\n",
        "}\n",
        "search_space = list(product(*param_grid.values()))\n",
        "print(f\"{len(search_space)} combinations to test\")"
      ],
      "metadata": {
        "id": "vX9suzozs4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(units, lr):\n",
        "    model = Sequential([\n",
        "        LSTM(units, input_shape=(SEQ_LEN, 1)),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "results = []\n",
        "best_rmse = np.inf\n",
        "best_model = None\n",
        "\n",
        "for units, lr, n_epochs in search_space:\n",
        "    print(f\"Training: units={units}, lr={lr}, epochs={n_epochs}\")\n",
        "    model = build_lstm(units, lr)\n",
        "    es = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "    model.fit(X_train, y_train,\n",
        "              epochs=n_epochs, batch_size=32,\n",
        "              validation_data=(X_val, y_val),\n",
        "              callbacks=[es], verbose=0)\n",
        "\n",
        "    # Validate\n",
        "    val_pred = model.predict(X_val, verbose=0)\n",
        "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "    results.append((units, lr, n_epochs, val_rmse))\n",
        "\n",
        "    # Keep best\n",
        "    if val_rmse < best_rmse:\n",
        "        best_rmse, best_model = val_rmse, model\n",
        "        best_params = (units, lr, n_epochs)\n",
        "        print(f\"  ðŸ”¥ New best RMSE: {best_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "c6NRmRrTtraw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best model\n",
        "best_model.save(\"best_lstm_manual.h5\")"
      ],
      "metadata": {
        "id": "MxzXlVTlucro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from itertools import product\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "rPHNrXFZqydS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load & Clean Data\n",
        "url = 'https://raw.githubusercontent.com/SankarSivan/Stock-Price-Prediction-Apple/main/AAPL.csv'\n",
        "df = pd.read_csv(url, parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "df = df[['Adj Close']].rename(columns={\"Adj Close\": \"adj_close\"})\n",
        "df.fillna(method=\"ffill\", inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0HcKSpyVq88e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create Sequences for Time Series Forecasting\n",
        "SEQ_LEN = 60\n",
        "def create_sequences(data, gap=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - SEQ_LEN - gap + 1):\n",
        "        X.append(data[i:i+SEQ_LEN])\n",
        "        y.append(data[i+SEQ_LEN+gap-1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df)\n",
        "\n",
        "X, y = create_sequences(scaled, gap=1)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)\n",
        "\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "y_train, y_val = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "GhoFw-c8reUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train SimpleRNN\n",
        "def build_rnn():\n",
        "    model = Sequential([\n",
        "        SimpleRNN(50, input_shape=(SEQ_LEN, 1)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "rnn_model = build_rnn()\n",
        "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "rnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n"
      ],
      "metadata": {
        "id": "O3gstjP9rwxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train LSTM (basic version)\n",
        "def build_lstm(units=50, lr=0.001):\n",
        "    model = Sequential([\n",
        "        LSTM(units, input_shape=(SEQ_LEN, 1)),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mse')\n",
        "    return model\n",
        "\n",
        "lstm_model = build_lstm()\n",
        "lstm_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val), callbacks=[es])\n"
      ],
      "metadata": {
        "id": "sALC8YDKrA38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Manual Hyperparameter Tuning for LSTM\n",
        "param_grid = {\n",
        "    \"units\": [32, 64],\n",
        "    \"lr\": [0.001, 0.005],\n",
        "    \"epochs\": [10, 20]\n",
        "}\n",
        "results = []\n",
        "best_rmse = float(\"inf\")\n",
        "best_model = None\n",
        "\n",
        "for units, lr, ep in product(*param_grid.values()):\n",
        "    print(f\"Training: units={units}, lr={lr}, epochs={ep}\")\n",
        "    model = build_lstm(units, lr)\n",
        "    model.fit(X_train, y_train, epochs=ep, batch_size=32, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
        "    results.append((units, lr, ep, rmse))\n",
        "\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_model = model\n",
        "        best_params = (units, lr, ep)\n",
        "\n",
        "print(\"Best:\", best_params, \"RMSE:\", best_rmse)\n",
        "best_model.save(\"best_lstm_manual.h5\")\n"
      ],
      "metadata": {
        "id": "PaWtBi25r19l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate and Plot\n",
        "def inverse_scale(y_scaled):\n",
        "    y_pad = np.hstack([y_scaled, np.zeros((len(y_scaled), 1))])\n",
        "    return scaler.inverse_transform(y_pad)[:, 0]\n",
        "\n",
        "val_pred = best_model.predict(X_val)\n",
        "val_true_inv = inverse_scale(y_val.reshape(-1, 1))\n",
        "val_pred_inv = inverse_scale(val_pred)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(val_true_inv, label=\"Actual Price\")\n",
        "plt.plot(val_pred_inv, label=\"Predicted Price\")\n",
        "plt.title(\"Prediction vs Actual\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "mae = mean_absolute_error(val_true_inv, val_pred_inv)\n",
        "rmse = np.sqrt(mean_squared_error(val_true_inv, val_pred_inv))\n",
        "print(f\"MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n"
      ],
      "metadata": {
        "id": "-yp-6KGfsClf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate and Plot\n",
        "def inverse_scale(y_scaled):\n",
        "    y_pad = np.hstack([y_scaled, np.zeros((len(y_scaled), 1))])\n",
        "    return scaler.inverse_transform(y_pad)[:, 0]\n",
        "\n",
        "val_pred = best_model.predict(X_val)\n",
        "val_true_inv = inverse_scale(y_val.reshape(-1, 1))\n",
        "val_pred_inv = inverse_scale(val_pred)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(val_true_inv, label=\"Actual Price\")\n",
        "plt.plot(val_pred_inv, label=\"Predicted Price\")\n",
        "plt.title(\"Prediction vs Actual\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "mae = mean_absolute_error(val_true_inv, val_pred_inv)\n",
        "rmse = np.sqrt(mean_squared_error(val_true_inv, val_pred_inv))\n",
        "print(f\"MAE: {mae:.2f} | RMSE: {rmse:.2f}\")"
      ],
      "metadata": {
        "id": "0gQPj5zAwTpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b61bca71"
      },
      "source": [
        "# Task\n",
        "Generate Python code to forecast future values using a trained LSTM model, visualize the forecast, and present the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb8f558f"
      },
      "source": [
        "## Prepare the last sequence\n",
        "\n",
        "### Subtask:\n",
        "Get the last `SEQ_LEN` data points from your scaled data to use as the initial input for forecasting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0108856d"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the last SEQ_LEN data points and reshape it for forecasting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dfd7600"
      },
      "source": [
        "last_sequence = scaled[-SEQ_LEN:].reshape(1, SEQ_LEN, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b33be656"
      },
      "source": [
        "## Predict future values\n",
        "\n",
        "### Subtask:\n",
        "Use a loop to predict the next data point using the current sequence, and then update the sequence by removing the oldest data point and adding the newly predicted one. Repeat this for the desired number of future days.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efe9f5b1"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the forecasting loop to predict future values using the trained LSTM model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2d2bd2c"
      },
      "source": [
        "future_days = 30\n",
        "future_predictions_scaled = []\n",
        "current_sequence = last_sequence.copy()\n",
        "\n",
        "for _ in range(future_days):\n",
        "    next_day_prediction_scaled = best_model.predict(current_sequence, verbose=0)\n",
        "    future_predictions_scaled.append(next_day_prediction_scaled[0, 0])\n",
        "    current_sequence = np.append(current_sequence[:, 1:, :], next_day_prediction_scaled.reshape(1, 1, 1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5be5ec82"
      },
      "source": [
        "## Inverse scale the predictions\n",
        "\n",
        "### Subtask:\n",
        "Transform the scaled future predictions back to the original price scale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b5c0536"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the scaled future predictions to the original price scale using the fitted scaler.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e422f32"
      },
      "source": [
        "future_predictions_scaled_np = np.array(future_predictions_scaled)\n",
        "future_predictions_scaled_reshaped = np.hstack([future_predictions_scaled_np.reshape(-1, 1), np.zeros((len(future_predictions_scaled_np), scaled.shape[1]-1))])\n",
        "future_predictions = scaler.inverse_transform(future_predictions_scaled_reshaped)[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56f1c83"
      },
      "source": [
        "## Visualize the forecast\n",
        "\n",
        "### Subtask:\n",
        "Visualize the forecast by plotting the historical data and the forecasted future values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "625ce184"
      },
      "source": [
        "**Reasoning**:\n",
        "Visualize the historical and forecasted stock prices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e26e63e4"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['adj_close'], label='Historical Price')\n",
        "forecast_start_index = len(df) - len(future_predictions)\n",
        "forecast_dates = pd.date_range(start=df.index[-1], periods=len(future_predictions) + 1)[1:]\n",
        "plt.plot(forecast_dates, future_predictions, label='Forecasted Price')\n",
        "plt.title('Stock Price Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Adjusted Close Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4354a92"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The last `SEQ_LEN` data points from the scaled data were successfully extracted and reshaped into a (1, `SEQ_LEN`, 1) NumPy array for use as the initial forecasting input.\n",
        "*   The LSTM model was used to predict future stock prices for 30 days by iteratively predicting the next data point and updating the input sequence.\n",
        "*   The scaled future predictions were successfully inverse transformed back to the original price scale.\n",
        "*   A plot was generated showing the historical adjusted close prices and the forecasted future adjusted close prices, providing a visual representation of the model's predictions.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Evaluate the accuracy of the forecast using appropriate metrics (e.g., RMSE, MAE) by comparing the predictions to actual future stock prices once available.\n",
        "*   Explore different LSTM model architectures, hyperparameters, or incorporate additional features (e.g., trading volume, news sentiment) to potentially improve forecasting performance.\n"
      ]
    }
  ]
}
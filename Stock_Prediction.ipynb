{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOmrSmk1wlOV2DokpGU06SZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SankarSivan/Stock-Price-Prediction-Apple/blob/main/Stock_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "tXR6_1DM4ZWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "F5ydpFUW4ZKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfiU-VF54A2R"
      },
      "outputs": [],
      "source": [
        "# prompt: import data from github\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/SankarSivan/Stock-Price-Prediction-Apple/main/AAPL.csv'\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PB-Gj7Np4W-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "LXfFObhL4W7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iU2jc2MYvejw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill missing values\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "id": "CrPTHzLS8R4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no remaining nulls\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "LDrpmlz-8UXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "metadata": {
        "id": "7xxUaTHQvq-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "1Li5X7jGv2yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "df['Date'] = df['Date'].apply(pd.to_datetime)"
      ],
      "metadata": {
        "id": "P-qm44wAwAHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ZpUkA_QvwmiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns= ['Open', 'High', 'Low', 'Adj Close', 'Volume'], inplace =True)"
      ],
      "metadata": {
        "id": "TIe52EkNwgF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tuHY1DaLxAil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close'].plot(figsize=(12,6))"
      ],
      "metadata": {
        "id": "6DGt6BWyxXP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Kcmap1u1yNsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df[['Close']])"
      ],
      "metadata": {
        "id": "1sIIpcT0NAnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n",
        "def create_sequences(data, seq_len=60, pred_gap=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len - pred_gap + 1):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        y.append(data[i+seq_len+pred_gap-1])  # Predicting gap days ahead\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "VJfWcLA_8q6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: For 1, 5, 10 day forecasts\n",
        "X_1, y_1 = create_sequences(scaled_data, pred_gap=1)\n",
        "X_5, y_5 = create_sequences(scaled_data, pred_gap=5)\n",
        "X_10, y_10 = create_sequences(scaled_data, pred_gap=10)"
      ],
      "metadata": {
        "id": "vr94Jp8e8veq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X, y = create_sequences(scaled_data, pred_gap=1)\n",
        "split = int(0.75 * len(X_1))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "GWqhSteM8xte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN Model"
      ],
      "metadata": {
        "id": "QHdMkaTF86K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "1kaFN8ls82RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(units=50, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "dKQkbmN982OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = build_rnn_model((X_train.shape[1], X_train.shape[2]))\n",
        "rnn_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "TE0wHhy482LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "p5zs1KlS9QTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "oQiATgJO82H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model building\n",
        "def build_lstm_model(input_shape, units = 50, Dropout_rate = 0.2, learning_rate = 0.001):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = units, return_sequences = False, input_shape = input_shape))\n",
        "    model.add(Dropout(Dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile ( optimizer = Adam(learning_rate = learning_rate), loss = 'mse')\n",
        "    return model\n",
        "\n",
        "# Model Excution\n",
        "lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
        "lstm_model.fit(X_train, y_train, epochs = 20, batch_size = 64, validation_split =0.2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xbRFVfXn82FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Models"
      ],
      "metadata": {
        "id": "hvKuhx_4Af-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "JMMsCTupiDb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test, scaler):\n",
        "    pred_scaled = model.predict(X_test)\n",
        "    pred = scaler.inverse_transform(np.concatenate([pred_scaled, np.zeros((len(pred_scaled), 1))], axis=1))[:,0]\n",
        "    true = scaler.inverse_transform(np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), 1))], axis=1))[:,0]\n",
        "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
        "    mae = mean_absolute_error(true, pred)\n",
        "    return rmse, mae\n",
        "\n",
        "rmse_rnn, mae_rnn = evaluate(rnn_model, X_test, y_test, scaler)\n",
        "rmse_lstm, mae_lstm = evaluate(lstm_model, X_test, y_test, scaler)\n",
        "\n",
        "print(f\"SimpleRNN RMSE: {rmse_rnn:.2f}, MAE: {mae_rnn:.2f}\")\n",
        "print(f\"LSTM RMSE: {rmse_lstm:.2f}, MAE: {mae_lstm:.2f}\")"
      ],
      "metadata": {
        "id": "oaYzwvw8iLvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict and inverse scale\n",
        "y_pred = lstm_model.predict(X_test)\n",
        "y_pred_rescaled = scaler.inverse_transform(np.concatenate([y_pred, np.zeros((len(y_pred),df.shape[1]-1))], axis = 1))[:,0]\n",
        "y_test_rescaled = scaler.inverse_transform(np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), df.shape[1]-1))], axis = 1)) [:,0]\n"
      ],
      "metadata": {
        "id": "Q1egnow99yUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "results = []"
      ],
      "metadata": {
        "id": "Q0BPc40PUWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the Actual vs Predicted\n",
        "plt.figure(figsize = (12,5) )\n",
        "plt.plot(y_test_rescaled, label = 'Actual')\n",
        "plt.plot(y_pred_rescaled, label = 'Predicted')\n",
        "plt.legend()\n",
        "plt.title(' Stock Price Prediction')"
      ],
      "metadata": {
        "id": "xUoItSRt9yRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV"
      ],
      "metadata": {
        "id": "Yvqvcjs0FHoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras tensorflow scikit-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QJ0Sk2uNYHHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
      ],
      "metadata": {
        "id": "nzJG1_gm9yOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDY99offEkCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLlA_gldEj__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FYNvz5ovkoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed2e96e"
      },
      "source": [
        "### Manual Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1615c31c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined and scaled\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'units': [50, 75],\n",
        "    'Dropout_rate': [0.1, 0.2],\n",
        "    'learning_rate': [0.01]\n",
        "}\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "# Manual Grid Search\n",
        "for units in param_grid['units']:\n",
        "    for dropout_rate in param_grid['Dropout_rate']:\n",
        "        for learning_rate in param_grid['learning_rate']:\n",
        "            print(f\"Training with units={units}, dropout_rate={dropout_rate}, learning_rate={learning_rate}\")\n",
        "\n",
        "            # Build the model with current hyperparameters\n",
        "            model = Sequential()\n",
        "            model.add(LSTM(units=units, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(1))\n",
        "            optimizer = Adam(learning_rate=learning_rate)\n",
        "            model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=0)\n",
        "\n",
        "            # Evaluate the model on the test set\n",
        "            loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "            print(f\"Test Loss: {loss}\")\n",
        "\n",
        "            results.append({\n",
        "                'units': units,\n",
        "                'dropout_rate': dropout_rate,\n",
        "                'learning_rate': learning_rate,\n",
        "                'test_loss': loss\n",
        "            })\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "                best_params = {'units': units, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate}\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_params)\n",
        "print(f\"Best Test Loss: {best_loss}\")\n",
        "\n",
        "# You can further analyze the results list to see all combinations and their performance\n",
        "# print(\"\\nAll Results:\")\n",
        "# for result in results:\n",
        "#     print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}